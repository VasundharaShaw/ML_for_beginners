{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-08T14:38:29.327078Z","iopub.execute_input":"2025-08-08T14:38:29.327430Z","iopub.status.idle":"2025-08-08T14:38:29.333585Z","shell.execute_reply.started":"2025-08-08T14:38:29.327401Z","shell.execute_reply":"2025-08-08T14:38:29.332271Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nimport pandas as pd\n\n# Load the dataset iris is a special kind of object called a Bunch, which is basically like a dictionary.\niris = load_iris()\n\nprint(iris.keys())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T14:40:36.183498Z","iopub.execute_input":"2025-08-08T14:40:36.183816Z","iopub.status.idle":"2025-08-08T14:40:36.191017Z","shell.execute_reply.started":"2025-08-08T14:40:36.183783Z","shell.execute_reply":"2025-08-08T14:40:36.190246Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Convert to a DataFrame for easy viewing\ndf = pd.DataFrame(iris.data, columns=iris.feature_names)\ndf['target'] = iris.target\ndf['target_name'] = df['target'].map(lambda i: iris.target_names[i])\n\n# Show the first 5 rows\nprint(df.head())  # shows first 5 rows nicely formatted\n\nprint(iris.feature_names) ## Gives you all the physical feature measurements of the Iris\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T14:38:29.771251Z","iopub.execute_input":"2025-08-08T14:38:29.771858Z","iopub.status.idle":"2025-08-08T14:38:29.785258Z","shell.execute_reply.started":"2025-08-08T14:38:29.771821Z","shell.execute_reply":"2025-08-08T14:38:29.784221Z"}},"outputs":[{"name":"stdout","text":"   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n0                5.1               3.5                1.4               0.2   \n1                4.9               3.0                1.4               0.2   \n2                4.7               3.2                1.3               0.2   \n3                4.6               3.1                1.5               0.2   \n4                5.0               3.6                1.4               0.2   \n\n   target target_name  \n0       0      setosa  \n1       0      setosa  \n2       0      setosa  \n3       0      setosa  \n4       0      setosa  \n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"##################################################################\n## This gives us a function to split our dataset into training and testing sets.\n## In ML, we train on one part of the data and test on another to see how well the model generalizes.\nfrom sklearn.model_selection import train_test_split \n## This imports the k-Nearest Neighbors (kNN) model.\n## It’s a simple ML model that classifies a data point by looking at its nearest neighbors in the training set.\nfrom sklearn.neighbors import KNeighborsClassifier\n## This is a helper function to check how well the model performs.\n## It compares predictions to actual values and tells us what percentage were correct.\nfrom sklearn.metrics import accuracy_score\n\n##################################################################\n# Step 1: Define features (X) and labels (y)\nX = df[iris.feature_names] ## X is your features (the 4 columns with measurements: sepal/petal length/width).\ny = df['target'] ## y is your label (which species the flower is: 0, 1, or 2).","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T14:42:00.277529Z","iopub.execute_input":"2025-08-08T14:42:00.277873Z","iopub.status.idle":"2025-08-08T14:42:00.284363Z","shell.execute_reply.started":"2025-08-08T14:42:00.277828Z","shell.execute_reply":"2025-08-08T14:42:00.283449Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Step 2: Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n\n## train_test_split --> splits the data.\n## test_size = 0.2 --> 20% of the data is saved for testing\n## random_state --> can be any integer, ensures the same split every time (for reproducibility).\n\n## X_train = training features\n\n## y_train = training labels\n\n## X_test = test features\n\n## y_test = test labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T14:47:39.814034Z","iopub.execute_input":"2025-08-08T14:47:39.814374Z","iopub.status.idle":"2025-08-08T14:47:39.821208Z","shell.execute_reply.started":"2025-08-08T14:47:39.814349Z","shell.execute_reply":"2025-08-08T14:47:39.820279Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Step 3: Create the model\nknn = KNeighborsClassifier(n_neighbors=5)\n\n## This creates a k-Nearest Neighbors classifier, using k = 3.\n## It means it will classify based on the 3 closest flowers in the training set.\n## You can try 1, 5, 7, etc. Odd numbers are often preferred to avoid ties.\n## A value too large (k = 100) might \"over-smooth\" the decision and hurt accuracy.\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T14:52:39.393257Z","iopub.execute_input":"2025-08-08T14:52:39.393572Z","iopub.status.idle":"2025-08-08T14:52:39.397735Z","shell.execute_reply.started":"2025-08-08T14:52:39.393550Z","shell.execute_reply":"2025-08-08T14:52:39.396955Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Step 4: Train the model\nknn.fit(X_train, y_train)\n## knn.fit() means “learn from the training data”.\n## It stores the training data and prepares the model for prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T14:52:39.618892Z","iopub.execute_input":"2025-08-08T14:52:39.619198Z","iopub.status.idle":"2025-08-08T14:52:39.627916Z","shell.execute_reply.started":"2025-08-08T14:52:39.619176Z","shell.execute_reply":"2025-08-08T14:52:39.627060Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"KNeighborsClassifier()","text/html":"<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"# Step 5: Predict on test data\ny_pred = knn.predict(X_test)\n\n## Now we ask the model to predict the species of the flowers in the test set.\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T14:52:39.867049Z","iopub.execute_input":"2025-08-08T14:52:39.867365Z","iopub.status.idle":"2025-08-08T14:52:39.878126Z","shell.execute_reply.started":"2025-08-08T14:52:39.867339Z","shell.execute_reply":"2025-08-08T14:52:39.877356Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"\n# Step 6: Evaluate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n## Compares y_pred (your model’s guesses) to y_test (the real answers).\n## Tells you how many the model got right — e.g., Accuracy: 0.97 = 97% correct.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T14:52:42.769244Z","iopub.execute_input":"2025-08-08T14:52:42.769897Z","iopub.status.idle":"2025-08-08T14:52:42.775332Z","shell.execute_reply.started":"2025-08-08T14:52:42.769869Z","shell.execute_reply":"2025-08-08T14:52:42.774514Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.90\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"## Step: Compare results \n\nfrom sklearn.metrics import accuracy_score\n\n# Predict on test data\ny_pred = knn.predict(X_test)\n\n# Combine predictions and actual values in a DataFrame\ncomparison = pd.DataFrame({\n    'Actual': y_test.values,\n    'Predicted': y_pred\n})\n\n# Map the numbers to species names\nspecies_names = iris.target_names\ncomparison['Actual'] = comparison['Actual'].map(lambda i: species_names[i])\ncomparison['Predicted'] = comparison['Predicted'].map(lambda i: species_names[i])\n\n# Add per-row accuracy (True/False or 1/0)\ncomparison['Correct'] = (comparison['Actual'] == comparison['Predicted']).astype(int)  # 1 = correct, 0 = wrong\n\nprint(comparison.head(10))\n\n# Optionally, show total model accuracy as well\naccuracy = comparison['Correct'].mean()\nprint(f\"\\nModel Accuracy: {accuracy:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T14:52:44.106507Z","iopub.execute_input":"2025-08-08T14:52:44.106804Z","iopub.status.idle":"2025-08-08T14:52:44.123476Z","shell.execute_reply.started":"2025-08-08T14:52:44.106775Z","shell.execute_reply":"2025-08-08T14:52:44.122591Z"}},"outputs":[{"name":"stdout","text":"       Actual   Predicted  Correct\n0   virginica   virginica        1\n1  versicolor  versicolor        1\n2      setosa      setosa        1\n3  versicolor  versicolor        1\n4   virginica  versicolor        0\n5      setosa      setosa        1\n6  versicolor  versicolor        1\n7  versicolor  versicolor        1\n8      setosa      setosa        1\n9  versicolor  versicolor        1\n\nModel Accuracy: 0.90\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"## model accuracy down to 70% for n = 99 whereas for n = 5 its 90%","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}